{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2edcbb7-4b86-453f-8aeb-86c5270e7c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import requests\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfd30cd-3609-492c-8924-ad38194b6632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables from the .env in the local environment\n",
    "load_dotenv()\n",
    "\n",
    "nyt_api_key = os.getenv(\"NYT_API_KEY\")\n",
    "tmdb_api_key = os.getenv(\"TMDB_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead08fb4-3c07-434d-91bf-f4f09f9534f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Access the New York Times API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aec271-1f3d-444a-a23e-d79d1f28a192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the base URL\n",
    "nyt_url = \"https://api.nytimes.com/svc/search/v2/articlesearch.json?\"\n",
    "\n",
    "# Filter for movie reviews with \"love\" in the headline\n",
    "# section_name should be \"Movies\"\n",
    "# type_of_material should be \"Review\"\n",
    "filter_query = 'section_name:\"Movies\" AND type_of_material:\"Review\" AND headline:\"love\"'\n",
    "\n",
    "# Use a sort filter, sort by newest\n",
    "sort = \"newest\"\n",
    "\n",
    "# Select the following fields to return:\n",
    "# headline, web_url, snippet, source, keywords, pub_date, byline, word_count\n",
    "field_list = \"headline,web_url,snippet,source,keywords,pub_date,byline,word_count\"\n",
    "\n",
    "# Search for reviews published between a begin and end date\n",
    "begin_date = \"20130101\"\n",
    "end_date = \"20230531\"\n",
    "\n",
    "\n",
    "# Build URL parameters\n",
    "nyt_params = {\n",
    "    'fq': filter_query,\n",
    "    'sort': sort,\n",
    "    'fl': field_list,\n",
    "    'begin_date': begin_date,\n",
    "    'end_date': end_date,\n",
    "    'api-key': nyt_api_key\n",
    "}\n",
    "\n",
    "# Function to build the query URL\n",
    "def build_query_url(base_url, params):\n",
    "    query_params = \"&\".join([f\"{key}={value}\" for key, value in params.items()])\n",
    "    return base_url + query_params\n",
    "\n",
    "\n",
    "# Print the first 5 rows of the reviews_list\n",
    "if reviews_list:\n",
    "    print(\"Preview of New York Times Data:\")\n",
    "    print(json.dumps(reviews_list[:5], indent=4))\n",
    "else:\n",
    "    print(\"No reviews were retrieved.\")\n",
    "\n",
    "\n",
    "# Convert reviews_list to a Pandas DataFrame using json_normalize()\n",
    "if reviews_list:\n",
    "    reviews_df = pd.json_normalize(reviews_list)\n",
    "    reviews_df['title'] = reviews_df['headline.main'].apply(lambda st: st[st.find(\"\\u2018\")+1:st.find(\"\\u2019 Review\")])\n",
    "else:\n",
    "    print(\"No reviews were retrieved.\")\n",
    "\n",
    "# Print the first 5 rows of the normalized DataFrame\n",
    "print(\"Normalized DataFrame (first 5 rows):\")\n",
    "print(reviews_df.head())\n",
    "\n",
    "# Create a list from the \"title\" column using to_list()\n",
    "# These titles will be used in the query for The Movie Database\n",
    "titles = reviews_df['title'].dropna().to_list()\n",
    "\n",
    "# Preview the titles in a readable format\n",
    "print(\"Preview of Titles List:\")\n",
    "for title in titles[:20]:  # Print the first 20 titles for readability\n",
    "    print(f\"'{title}'\")\n",
    "\n",
    "# Build the query URL\n",
    "query_url = build_query_url(nyt_url, nyt_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b0f689-3f31-455b-89d5-665ae68b8347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the reviews\n",
    "reviews_list = []\n",
    "\n",
    "# loop through pages 0-19\n",
    "\n",
    "    # create query with a page number\n",
    "    # API results show 10 articles at a time\n",
    "    # Make a \"GET\" request and retrieve the JSON\n",
    "    # Add a twelve second interval between queries to stay within API query limits\n",
    "for page in range(20):\n",
    "    nyt_params['page'] = page\n",
    "    query_params = \"&\".join([f\"{key}={value}\" for key, value in nyt_params.items()])\n",
    "    query_url = nyt_url + query_params\n",
    "    response = requests.get(query_url)\n",
    "    time.sleep(12)\n",
    "# Try and save the reviews to the reviews_list\n",
    " # loop through the reviews[\"response\"][\"docs\"] and append each review to the list\n",
    " # Print the page that was just retrieved\n",
    "# Print the page number that had no results then break from the loop\n",
    "    \n",
    "    try:\n",
    "        reviews = response.json()\n",
    "        for review in reviews[\"response\"][\"docs\"]:\n",
    "            reviews_list.append(review)\n",
    "        print(f\"Successfully retrieved page {page}\")\n",
    "    except Exception as e:\n",
    "        print(f\"No results on page {page}, exiting loop\")\n",
    "        print(f\"Error: {e}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96492134-00bc-4bab-b237-fb6e1c959f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the first 5 results in JSON format\n",
    "# Use json.dumps with argument indent=4 to format data\n",
    "print(json.dumps(reviews_list[:5], indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9511a7a-6db3-4bc3-a6f9-4a007065fa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert reviews_list to a Pandas DataFrame using json_normalize()\n",
    "reviews_df = pd.json_normalize(reviews_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b761386-04f1-4a4c-a2fe-74a29f3c5938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the title from the \"headline.main\" column and\n",
    "# save it to a new column \"title\"\n",
    "# Title is between unicode characters \\u2018 and \\u2019. \n",
    "# End string should include \" Review\" to avoid cutting title early\n",
    "reviews_df['title'] = reviews_df['headline.main'].apply(lambda st: st[st.find(\"\\u2018\")+1:st.find(\"\\u2019 Review\")])\n",
    "reviews_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5ac9e6-89f4-4c83-8315-641f347f2155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list from the \"title\" column using to_list()\n",
    "# These titles will be used in the query for The Movie Database\n",
    "titles = reviews_df['title'].dropna().to_list()\n",
    "print(\"Preview of Titles List:\")\n",
    "for title in titles[:10]:  # Print the first 20 titles for readability\n",
    "    print(f\"'{title}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0032f1-04a1-40ac-acc2-d70cf9d83a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Access The Movie Database API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc235df-890d-4f1d-a9df-604def85dceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare The Movie Database query\n",
    "# Directly set the TMDb API key string\n",
    "# Set the TMDb API key and base URLs\n",
    "tmdb_search_url = \"https://api.themoviedb.org/3/search/movie?query=\"\n",
    "tmdb_movie_url = \"https://api.themoviedb.org/3/movie/\"\n",
    "tmdb_key_string = \"&api_key=\" + tmdb_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345ba7e2-c59d-4dfa-a1e8-d5913572cda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the TMDb results\n",
    "tmdb_movies_list = []\n",
    "\n",
    "# Create a request counter to sleep the requests after a multiple of 50 requests\n",
    "request_counter = 1\n",
    "# Loop through the titles\n",
    "# Check if we need to sleep before making a request    \n",
    "titles = reviews_df['title'].dropna().to_list()\n",
    "\n",
    "for title in titles:\n",
    "    if request_counter % 50 == 0:\n",
    "        print(\"Sleeping for 60 seconds to avoid hitting rate limits...\")\n",
    "        time.sleep(60)\n",
    "        \n",
    "# Perform a \"GET\" request for The Movie Database    \n",
    "# Build the search query URL\n",
    "    search_query_url = f\"{tmdb_search_url}{title}{tmdb_key_string}\"\n",
    "    search_response = requests.get(search_query_url)\n",
    "\n",
    "   # Add 1 to the request counter\n",
    "    \n",
    "    request_counter += 1\n",
    "\n",
    "\n",
    "    # Include a try clause to search for the full movie details.\n",
    "    # Use the except clause to print out a statement if a movie\n",
    "    # is not found.\n",
    "    \n",
    "    try:\n",
    "        search_data = search_response.json()\n",
    "        if not search_data['results']:\n",
    "            print(f\"No movie found for title: {title}\")\n",
    "            continue\n",
    "        \n",
    "        # Get movie id\n",
    "        movie_id = search_data['results'][0]['id']\n",
    "        \n",
    "        # Build the movie details query URL\n",
    "        movie_query_url = f\"{tmdb_movie_url}{movie_id}?api_key={tmdb_api_key}\"\n",
    "        movie_response = requests.get(movie_query_url)\n",
    "        movie_data = movie_response.json()\n",
    "        \n",
    "        genres = [genre['name'] for genre in movie_data.get('genres', [])]\n",
    "        spoken_languages = [lang['english_name'] for lang in movie_data.get('spoken_languages', [])]\n",
    "        production_countries = [country['name'] for country in movie_data.get('production_countries', [])]\n",
    "        \n",
    "        movie_info = {\n",
    "            'title': title,\n",
    "            'original_title': movie_data.get('original_title', ''),\n",
    "            'budget': movie_data.get('budget', ''),\n",
    "            'original_language': movie_data.get('original_language', ''),\n",
    "            'homepage': movie_data.get('homepage', ''),\n",
    "            'overview': movie_data.get('overview', ''),\n",
    "            'popularity': movie_data.get('popularity', ''),\n",
    "            'runtime': movie_data.get('runtime', ''),\n",
    "            'revenue': movie_data.get('revenue', ''),\n",
    "            'release_date': movie_data.get('release_date', ''),\n",
    "            'vote_average': movie_data.get('vote_average', ''),\n",
    "            'vote_count': movie_data.get('vote_count', ''),\n",
    "            'genres': \", \".join(genres),\n",
    "            'spoken_languages': \", \".join(spoken_languages),\n",
    "            'production_countries': \", \".join(production_countries)\n",
    "        }\n",
    "        tmdb_movies_list.append(movie_info)\n",
    "        print(f\"Successfully retrieved details for title: {title}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to retrieve details for title: {title}\")\n",
    "        print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad14cac-cb2f-43f5-badb-4701511d655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the results to a DataFrame\n",
    "tmdb_df = pd.DataFrame(tmdb_movies_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71fa88d-7a39-4676-afd2-693250c23e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preview the first 5 results in JSON format\n",
    "# Use json.dumps with argument indent=4 to format data\n",
    "print(\"Preview of TMDb Data:\")\n",
    "print(json.dumps(tmdb_movies_list[:5], indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe923923-7585-4caf-9636-7a7d38a0e7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the results to a DataFrame\n",
    "tmdb_df = pd.DataFrame(tmdb_movies_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8b5a57-06c8-4405-a350-927a533c37b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge and Clean the Data for Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d6834d-7915-41dc-9dd0-66426e03cb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the New York Times reviews and TMDB DataFrames on title\n",
    "merged_df = pd.merge(reviews_df, tmdb_df, on='title', how='inner')\n",
    "\n",
    "# Print the head of the merged DataFrame to check the result\n",
    "print(\"Preview of Merged Data:\")\n",
    "print(merged_df.head())\n",
    "\n",
    "# Verify the merge by checking for the presence of key columns\n",
    "print(\"Columns in the merged DataFrame:\")\n",
    "print(merged_df.columns)\n",
    "\n",
    "# Check for unexpected NaN values\n",
    "print(\"Number of NaN values in each column:\")\n",
    "print(merged_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a33b051-cc9f-4b9b-94f2-b6d7e938a434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the columns that need fixing\n",
    "columns_to_fix = ['genres', 'spoken_languages', 'production_countries']\n",
    "\n",
    "# Create a list of characters to remove\n",
    "characters_to_remove = [\"[\", \"]\", \"'\"]\n",
    "\n",
    "# Loop through the list of columns to fix\n",
    "for column in columns_to_fix:\n",
    "    # Ensure the column contains string representations of lists\n",
    "    merged_df[column] = merged_df[column].astype(str)\n",
    "    \n",
    "    # Loop through characters to remove\n",
    "    for char in characters_to_remove:\n",
    "        merged_df[column] = merged_df[column].str.replace(char, \"\", regex=False)\n",
    "\n",
    "# Display the fixed DataFrame\n",
    "print(\"Fixed Merged DataFrame:\")\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333feddc-7ad3-441e-af8c-da8d135b8a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the \"byline.person\" column if it exists\n",
    "columns_to_drop = [col for col in merged_df.columns if 'byline.person' in col]\n",
    "if columns_to_drop:\n",
    "    merged_df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9594fd09-4fd7-4c5e-b9b2-26903e6b04d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Columns in the merged DataFrame after attempting to drop specified columns:\")\n",
    "print(merged_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7866a49-7366-48e0-8b8b-b16c9f869b16",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Remove duplicate rows and reset the index\n",
    "merged_df.drop_duplicates(inplace=True)\n",
    "merged_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3d5b47-b4b1-448e-a45d-35a014599f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data to CSV without the index\n",
    "merged_df.to_csv('merged_cleaned_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
